package agent

import (
	"context"
	"fmt"
	"log"
	"math/rand"
	"strings"
	"sync"
	"time"

	contextmgr "alex/internal/context"
	"alex/internal/llm"
	"alex/internal/session"
)

// CachedCompressionResult - LLMå‹ç¼©ç»“æœç¼“å­˜
type CachedCompressionResult struct {
	Summary      *session.Message
	Timestamp    time.Time
	InputHash    string
	MessageCount int
}

// MessageProcessor ç»Ÿä¸€çš„æ¶ˆæ¯å¤„ç†å™¨ï¼Œæ•´åˆæ‰€æœ‰æ¶ˆæ¯ç›¸å…³åŠŸèƒ½
type MessageProcessor struct {
	contextMgr     *contextmgr.ContextManager
	sessionManager *session.Manager
	tokenEstimator *TokenEstimator

	// LLMå‹ç¼©ç¼“å­˜ä¼˜åŒ–
	compressionCache map[string]*CachedCompressionResult
	compressionMutex sync.RWMutex
	cacheExpiry      time.Duration
}

// NewMessageProcessor åˆ›å»ºç»Ÿä¸€çš„æ¶ˆæ¯å¤„ç†å™¨
func NewMessageProcessor(llmClient llm.Client, sessionManager *session.Manager) *MessageProcessor {
	// åˆ›å»ºä¸Šä¸‹æ–‡ç®¡ç†å™¨
	contextConfig := &contextmgr.ContextLengthConfig{
		MaxTokens:              8000,
		SummarizationThreshold: 6000,
		CompressionRatio:       0.3,
		PreserveSystemMessages: true,
	}

	return &MessageProcessor{
		contextMgr:     contextmgr.NewContextManager(llmClient, contextConfig),
		sessionManager: sessionManager,
		tokenEstimator: NewTokenEstimator(),

		// åˆå§‹åŒ–LLMå‹ç¼©ç¼“å­˜
		compressionCache: make(map[string]*CachedCompressionResult),
		cacheExpiry:      30 * time.Minute, // 30åˆ†é’Ÿç¼“å­˜è¿‡æœŸ
	}
}

// ========== æ¶ˆæ¯è½¬æ¢ ==========

// ConvertSessionToLLM å°† session æ¶ˆæ¯è½¬æ¢ä¸º LLM æ ¼å¼
func (mp *MessageProcessor) ConvertSessionToLLM(sessionMessages []*session.Message) []llm.Message {
	messages := make([]llm.Message, 0, len(sessionMessages))

	for _, msg := range sessionMessages {
		llmMsg := llm.Message{
			Role:    msg.Role,
			Content: msg.Content,
		}

		// å¤„ç†å·¥å…·è°ƒç”¨
		if len(msg.ToolCalls) > 0 {
			llmMsg.ToolCalls = make([]llm.ToolCall, 0, len(msg.ToolCalls))
			for _, tc := range msg.ToolCalls {
				llmMsg.ToolCalls = append(llmMsg.ToolCalls, llm.ToolCall{
					ID:   tc.ID,
					Type: "function",
					Function: llm.Function{
						Name: tc.Name,
					},
				})
			}
		}

		// å¤„ç†å·¥å…·è°ƒç”¨ ID
		if msg.Role == "tool" {
			if callID, ok := msg.Metadata["tool_call_id"].(string); ok {
				llmMsg.ToolCallId = callID
			}
		}

		messages = append(messages, llmMsg)
	}

	return messages
}

// ConvertLLMToSession å°† LLM æ¶ˆæ¯è½¬æ¢ä¸º session æ ¼å¼
func (mp *MessageProcessor) ConvertLLMToSession(llmMessages []llm.Message) []*session.Message {
	messages := make([]*session.Message, 0, len(llmMessages))

	for _, msg := range llmMessages {
		sessionMsg := &session.Message{
			Role:      msg.Role,
			Content:   msg.Content,
			Metadata:  make(map[string]interface{}),
			Timestamp: time.Now(),
		}

		// å¤„ç†å·¥å…·è°ƒç”¨
		if len(msg.ToolCalls) > 0 {
			sessionMsg.ToolCalls = make([]session.ToolCall, 0, len(msg.ToolCalls))
			for _, tc := range msg.ToolCalls {
				sessionMsg.ToolCalls = append(sessionMsg.ToolCalls, session.ToolCall{
					ID:   tc.ID,
					Name: tc.Function.Name,
				})
			}
		}

		// å¤„ç†å·¥å…·è°ƒç”¨ ID
		if msg.Role == "tool" && msg.ToolCallId != "" {
			sessionMsg.Metadata["tool_call_id"] = msg.ToolCallId
		}

		messages = append(messages, sessionMsg)
	}

	return messages
}

// formatMemoryContent æ ¼å¼åŒ–å†…å­˜å†…å®¹

// ========== æ¶ˆæ¯å‹ç¼© ==========

// compressMessages æ™ºèƒ½å‹ç¼©æ¶ˆæ¯
func (mp *MessageProcessor) compressMessages(sessionMessages []*session.Message) []*session.Message {
	const (
		MaxMessages = 80   // é™ä½æ¶ˆæ¯æ•°é‡é˜ˆå€¼
		MaxTokens   = 6000 // é™ä½tokené˜ˆå€¼ï¼Œé¢„ç•™ç©ºé—´
		RecentKeep  = 10   // ä¿ç•™æ›´å¤šæœ€è¿‘æ¶ˆæ¯
	)

	// æ£€æŸ¥æ˜¯å¦éœ€è¦å‹ç¼© - æ›´æ—©è§¦å‘
	estimatedTokens := mp.tokenEstimator.EstimateSessionMessages(sessionMessages)
	if len(sessionMessages) <= 10 || estimatedTokens <= 3000 {
		return sessionMessages // æ¶ˆæ¯å¾ˆå°‘æ—¶ä¸å‹ç¼©
	}

	// æ¸è¿›å¼å‹ç¼©ï¼šæ ¹æ®å‹åŠ›ç­‰çº§é€‰æ‹©ç­–ç•¥
	if len(sessionMessages) > MaxMessages || estimatedTokens > MaxTokens {
		log.Printf("[INFO] High pressure compression triggered: %d messages, estimated %d tokens",
			len(sessionMessages), estimatedTokens)
		return mp.aggressiveCompress(sessionMessages, RecentKeep)
	}

	// ä¸­ç­‰å‹åŠ›ï¼šä¿ç•™é‡è¦æ¶ˆæ¯å’Œæœ€è¿‘æ¶ˆæ¯
	if len(sessionMessages) > 40 || estimatedTokens > 4000 {
		log.Printf("[INFO] Medium pressure compression triggered: %d messages, estimated %d tokens",
			len(sessionMessages), estimatedTokens)
		return mp.moderateCompress(sessionMessages, RecentKeep)
	}

	// ä½å‹åŠ›ï¼šåªåšè½»å¾®æ•´ç†
	if len(sessionMessages) > 25 || estimatedTokens > 3500 {
		log.Printf("[INFO] Light compression triggered: %d messages, estimated %d tokens",
			len(sessionMessages), estimatedTokens)
		return mp.lightCompress(sessionMessages, RecentKeep)
	}

	return sessionMessages
}

// aggressiveCompress æ¿€è¿›å‹ç¼©ï¼šç”Ÿæˆæ‘˜è¦
func (mp *MessageProcessor) aggressiveCompress(messages []*session.Message, recentKeep int) []*session.Message {
	if len(messages) <= recentKeep {
		return messages
	}

	// ä¿ç•™æœ€è¿‘çš„æ¶ˆæ¯
	recentMessages := messages[len(messages)-recentKeep:]

	// å¯¹å…¶ä½™æ¶ˆæ¯åˆ›å»ºæ‘˜è¦
	oldMessages := messages[:len(messages)-recentKeep]
	summaryMsg := mp.createMessageSummary(oldMessages)

	var result []*session.Message
	if summaryMsg != nil {
		result = append(result, summaryMsg)
	}
	result = append(result, recentMessages...)

	log.Printf("[INFO] Aggressive compression: %d -> %d messages", len(messages), len(result))
	return result
}

// moderateCompress ä¸­ç­‰å‹ç¼©ï¼šé€‰æ‹©æ€§ä¿ç•™é‡è¦æ¶ˆæ¯
func (mp *MessageProcessor) moderateCompress(messages []*session.Message, recentKeep int) []*session.Message {
	if len(messages) <= recentKeep+5 {
		return messages
	}

	// ä¿ç•™æœ€è¿‘çš„æ¶ˆæ¯
	recentMessages := messages[len(messages)-recentKeep:]

	// ä»æ—§æ¶ˆæ¯ä¸­é€‰æ‹©é‡è¦çš„æ¶ˆæ¯
	oldMessages := messages[:len(messages)-recentKeep]
	importantMessages := mp.selectImportantMessages(oldMessages, 5)

	var result []*session.Message
	result = append(result, importantMessages...)
	result = append(result, recentMessages...)

	log.Printf("[INFO] Moderate compression: %d -> %d messages", len(messages), len(result))
	return result
}

// lightCompress è½»åº¦å‹ç¼©ï¼šç§»é™¤ä½ä»·å€¼æ¶ˆæ¯
func (mp *MessageProcessor) lightCompress(messages []*session.Message, recentKeep int) []*session.Message {
	var result []*session.Message

	for i, msg := range messages {
		// æ€»æ˜¯ä¿ç•™æœ€è¿‘çš„æ¶ˆæ¯
		if i >= len(messages)-recentKeep {
			result = append(result, msg)
			continue
		}

		// ç§»é™¤ä½ä»·å€¼æ¶ˆæ¯
		if mp.isLowValueMessage(msg) {
			continue
		}

		result = append(result, msg)
	}

	log.Printf("[INFO] Light compression: %d -> %d messages", len(messages), len(result))
	return result
}

// selectImportantMessages é€‰æ‹©é‡è¦æ¶ˆæ¯
func (mp *MessageProcessor) selectImportantMessages(messages []*session.Message, maxCount int) []*session.Message {
	if len(messages) <= maxCount {
		return messages
	}

	// è®¡ç®—æ¶ˆæ¯é‡è¦æ€§åˆ†æ•°
	type msgWithScore struct {
		msg   *session.Message
		score float64
	}

	var scored []msgWithScore
	for _, msg := range messages {
		score := mp.calculateMessageImportance(msg)
		scored = append(scored, msgWithScore{msg, score})
	}

	// æŒ‰åˆ†æ•°æ’åº
	for i := 0; i < len(scored)-1; i++ {
		for j := i + 1; j < len(scored); j++ {
			if scored[i].score < scored[j].score {
				scored[i], scored[j] = scored[j], scored[i]
			}
		}
	}

	// é€‰æ‹©å‰maxCountä¸ª
	var result []*session.Message
	for i := 0; i < maxCount && i < len(scored); i++ {
		result = append(result, scored[i].msg)
	}

	return result
}

// isLowValueMessage åˆ¤æ–­æ˜¯å¦ä¸ºä½ä»·å€¼æ¶ˆæ¯
func (mp *MessageProcessor) isLowValueMessage(msg *session.Message) bool {
	content := strings.TrimSpace(msg.Content)

	// ç©ºæ¶ˆæ¯ä¸è¢«è®¤ä¸ºæ˜¯ä½ä»·å€¼æ¶ˆæ¯ï¼ˆåœ¨åˆ«å¤„å¤„ç†ï¼‰
	if len(content) == 0 {
		return false
	}

	// çŸ­æ¶ˆæ¯é€šå¸¸ä»·å€¼è¾ƒä½
	if len(content) < 10 {
		return true
	}

	// çº¯ç¡®è®¤æ¶ˆæ¯
	lowValuePhrases := []string{
		"å¥½çš„", "OK", "ok", "æ˜¯çš„", "æ”¶åˆ°", "æ˜ç™½", "äº†è§£", "è°¢è°¢",
		"å¥½", "è¡Œ", "æ²¡é—®é¢˜", "å¯ä»¥", "ç»§ç»­", "next", "yes", "no",
	}

	contentLower := strings.ToLower(content)
	for _, phrase := range lowValuePhrases {
		if contentLower == strings.ToLower(phrase) {
			return true
		}
	}

	return false
}

// calculateMessageImportance è®¡ç®—æ¶ˆæ¯é‡è¦æ€§
func (mp *MessageProcessor) calculateMessageImportance(msg *session.Message) float64 {
	score := 0.0
	content := msg.Content

	// é•¿åº¦å› å­
	score += float64(len(content)) * 0.01

	// ä»£ç å—åŠ åˆ†
	if strings.Contains(content, "```") {
		score += 10.0
	}

	// å·¥å…·è°ƒç”¨åŠ åˆ†
	if len(msg.ToolCalls) > 0 {
		score += float64(len(msg.ToolCalls)) * 5.0
	}

	// é”™è¯¯ä¿¡æ¯åŠ åˆ†
	if strings.Contains(strings.ToLower(content), "error") ||
		strings.Contains(strings.ToLower(content), "é”™è¯¯") {
		score += 5.0
	}

	// é—®é¢˜å’Œè§£å†³æ–¹æ¡ˆåŠ åˆ†
	if strings.Contains(content, "?") || strings.Contains(content, "ï¼Ÿ") {
		score += 5.0
	}

	// å…³é”®è¯åŠ åˆ†
	keywords := []string{"implement", "how", "why", "what", "where", "when", "function", "method", "error", "issue", "problem"}
	contentLower := strings.ToLower(content)
	for _, keyword := range keywords {
		if strings.Contains(contentLower, keyword) {
			score += 2.0
		}
	}

	return score
}

// createMessageSummary åˆ›å»ºæ¶ˆæ¯æ‘˜è¦
func (mp *MessageProcessor) createMessageSummary(messages []*session.Message) *session.Message {
	if len(messages) == 0 {
		return nil
	}

	// å°è¯• LLM æ‘˜è¦
	if summary := mp.createLLMSummary(messages); summary != nil {
		return summary
	}

	// å›é€€åˆ°ç»Ÿè®¡æ‘˜è¦
	return mp.createStatisticalSummary(messages)
}

// createLLMSummary ä½¿ç”¨ LLM åˆ›å»ºæ‘˜è¦ - ä¼˜åŒ–ç‰ˆæœ¬å¸¦ç¼“å­˜
func (mp *MessageProcessor) createLLMSummary(messages []*session.Message) *session.Message {
	// é¦–å…ˆæ£€æŸ¥ç¼“å­˜
	if cachedSummary := mp.getCachedCompressionResult(messages); cachedSummary != nil {
		return cachedSummary
	}

	// æ™ºèƒ½å†³ç­–ï¼šæ˜¯å¦ä½¿ç”¨LLMå‹ç¼©
	if !mp.shouldUseLLMCompression(messages) {
		log.Printf("[INFO] Using statistical summary instead of LLM for %d messages", len(messages))
		return mp.createStatisticalSummary(messages)
	}

	llmClient, err := llm.GetLLMInstance(llm.BasicModel)
	if err != nil {
		log.Printf("[WARN] Failed to get LLM instance for summary: %v", err)
		return mp.createStatisticalSummary(messages) // é™çº§åˆ°ç»Ÿè®¡æ‘˜è¦
	}

	// æ„å»ºå‹ç¼©è¾“å…¥
	conversationText := mp.buildSummaryInput(messages)
	if len(conversationText) == 0 {
		return nil
	}

	// æ„å»ºä¼˜åŒ–çš„æ‘˜è¦è¯·æ±‚
	request := &llm.ChatRequest{
		Messages: []llm.Message{
			{
				Role:    "system",
				Content: mp.buildOptimizedSystemPrompt(),
			},
			{
				Role:    "user",
				Content: mp.buildOptimizedSummaryPrompt(conversationText, len(messages)),
			},
		},
		ModelType: llm.BasicModel,
		Config: &llm.Config{
			Temperature: 0.3,  // é™ä½æ¸©åº¦æé«˜ä¸€è‡´æ€§
			MaxTokens:   1000, // å‡å°‘æœ€å¤§tokenæ•°
		},
	}

	ctx, cancel := context.WithTimeout(context.Background(), 15*time.Second) // å‡å°‘è¶…æ—¶æ—¶é—´
	defer cancel()

	response, err := llmClient.Chat(ctx, request)
	if err != nil || len(response.Choices) == 0 {
		log.Printf("[WARN] LLM summary failed: %v, falling back to statistical summary", err)
		return mp.createStatisticalSummary(messages) // é™çº§åˆ°ç»Ÿè®¡æ‘˜è¦
	}

	summaryContent := strings.TrimSpace(response.Choices[0].Message.Content)
	if len(summaryContent) == 0 {
		return mp.createStatisticalSummary(messages) // é™çº§åˆ°ç»Ÿè®¡æ‘˜è¦
	}

	summary := &session.Message{
		Role:    "system",
		Content: summaryContent,
		Metadata: map[string]interface{}{
			"type":               "llm_summary",
			"original_count":     len(messages),
			"summary_timestamp":  time.Now().Unix(),
			"compression_method": "llm",
		},
		Timestamp: time.Now(),
	}

	// ç¼“å­˜å‹ç¼©ç»“æœ
	mp.setCachedCompressionResult(messages, summary)

	log.Printf("[INFO] LLM summary created for %d messages, cached for future use", len(messages))
	return summary
}

// ========== LLMå‹ç¼©ä¼˜åŒ–æ–¹æ³• ==========

// getCachedCompressionResult è·å–ç¼“å­˜çš„å‹ç¼©ç»“æœ
func (mp *MessageProcessor) getCachedCompressionResult(messages []*session.Message) *session.Message {
	if len(messages) == 0 {
		return nil
	}

	// æ„å»ºç¼“å­˜é”®
	inputHash := mp.buildMessageHash(messages)

	mp.compressionMutex.RLock()
	defer mp.compressionMutex.RUnlock()

	if cached, exists := mp.compressionCache[inputHash]; exists {
		// æ£€æŸ¥ç¼“å­˜æ˜¯å¦è¿‡æœŸ
		if time.Since(cached.Timestamp) < mp.cacheExpiry {
			log.Printf("[DEBUG] Cache hit for compression of %d messages", len(messages))
			return cached.Summary
		}
		// ç¼“å­˜è¿‡æœŸï¼Œåˆ é™¤
		delete(mp.compressionCache, inputHash)
	}

	return nil
}

// setCachedCompressionResult è®¾ç½®ç¼“å­˜çš„å‹ç¼©ç»“æœ
func (mp *MessageProcessor) setCachedCompressionResult(messages []*session.Message, summary *session.Message) {
	if len(messages) == 0 || summary == nil {
		return
	}

	inputHash := mp.buildMessageHash(messages)

	mp.compressionMutex.Lock()
	defer mp.compressionMutex.Unlock()

	mp.compressionCache[inputHash] = &CachedCompressionResult{
		Summary:      summary,
		Timestamp:    time.Now(),
		InputHash:    inputHash,
		MessageCount: len(messages),
	}
}

// buildMessageHash ä¸ºæ¶ˆæ¯åˆ—è¡¨æ„å»ºå“ˆå¸Œ
func (mp *MessageProcessor) buildMessageHash(messages []*session.Message) string {
	var hashInput strings.Builder
	for i, msg := range messages {
		if i > 0 {
			hashInput.WriteString("|")
		}
		hashInput.WriteString(msg.Role)
		hashInput.WriteString(":")
		// åªä½¿ç”¨å†…å®¹çš„å‰100ä¸ªå­—ç¬¦æ¥æ„å»ºå“ˆå¸Œï¼Œé¿å…è¿‡é•¿
		content := msg.Content
		if len(content) > 100 {
			content = content[:100]
		}
		hashInput.WriteString(content)
	}
	return fmt.Sprintf("%x", hashInput.String())
}

// shouldUseLLMCompression æ™ºèƒ½å†³ç­–æ˜¯å¦ä½¿ç”¨LLMå‹ç¼©
func (mp *MessageProcessor) shouldUseLLMCompression(messages []*session.Message) bool {
	// æ¶ˆæ¯æ•°é‡å¤ªå°‘ä¸å€¼å¾—LLMå‹ç¼©
	if len(messages) < 10 {
		return false
	}

	// ä¼°ç®—tokenæ•°é‡
	estimatedTokens := mp.tokenEstimator.EstimateSessionMessages(messages)

	// å†…å®¹å¤ªå°‘ä¸å€¼å¾—LLMå‹ç¼©
	if estimatedTokens < 2000 {
		return false
	}

	// æ£€æŸ¥å†…å®¹å¤æ‚åº¦
	complexity := mp.calculateContentComplexity(messages)

	// é«˜å¤æ‚åº¦å†…å®¹ä½¿ç”¨LLMå‹ç¼©
	if complexity > 0.7 {
		return true
	}

	// ä¸­ç­‰å¤æ‚åº¦ä¸”æ¶ˆæ¯æ•°é‡å¤šæ—¶ä½¿ç”¨LLMå‹ç¼©
	if complexity > 0.5 && len(messages) > 20 {
		return true
	}

	// å…¶ä»–æƒ…å†µä½¿ç”¨ç»Ÿè®¡æ‘˜è¦
	return false
}

// calculateContentComplexity è®¡ç®—å†…å®¹å¤æ‚åº¦
func (mp *MessageProcessor) calculateContentComplexity(messages []*session.Message) float64 {
	var totalScore float64
	var totalLength int

	for _, msg := range messages {
		content := msg.Content
		totalLength += len(content)

		// ä»£ç å†…å®¹å¤æ‚åº¦æ›´é«˜
		if strings.Contains(content, "```") || strings.Contains(content, "function") || strings.Contains(content, "class") {
			totalScore += 1.0
		}

		// é”™è¯¯æ¶ˆæ¯å¤æ‚åº¦é«˜
		if strings.Contains(strings.ToLower(content), "error") || strings.Contains(strings.ToLower(content), "exception") {
			totalScore += 0.8
		}

		// å·¥å…·è°ƒç”¨å¤æ‚åº¦é«˜
		if len(msg.ToolCalls) > 0 {
			totalScore += 0.6
		}

		// é•¿å†…å®¹å¤æ‚åº¦é«˜
		if len(content) > 500 {
			totalScore += 0.4
		}
	}

	if len(messages) == 0 {
		return 0
	}

	return totalScore / float64(len(messages))
}

// buildOptimizedSystemPrompt æ„å»ºä¼˜åŒ–çš„ç³»ç»Ÿæç¤º
func (mp *MessageProcessor) buildOptimizedSystemPrompt() string {
	return `Create a concise summary that preserves key information while significantly reducing length.
Focus on:
1. Important decisions and outcomes
2. Key technical details and solutions
3. Error patterns and fixes
4. Critical context for future reference

Output format: Brief paragraph format, no bullet points.
Target: 70-80% length reduction while maintaining essential information.`
}

// buildOptimizedSummaryPrompt æ„å»ºä¼˜åŒ–çš„æ‘˜è¦æç¤º
func (mp *MessageProcessor) buildOptimizedSummaryPrompt(conversationText string, messageCount int) string {
	return fmt.Sprintf(`Summarize this conversation thread of %d messages:

%s

Create a concise summary that captures the essential information while reducing length by 70-80%%. Focus on key decisions, technical solutions, and important context.`, messageCount, conversationText)
}

// buildSummaryInput æ„å»ºæ‘˜è¦è¾“å…¥
func (mp *MessageProcessor) buildSummaryInput(messages []*session.Message) string {
	var parts []string

	for i, msg := range messages {
		if msg.Role == "system" {
			if msgType, ok := msg.Metadata["type"].(string); ok {
				if strings.Contains(msgType, "summary") {
					continue
				}
			}
		}

		content := msg.Content
		if len(content) > 500 {
			content = content[:500] + "...[truncated]"
		}

		roleName := strings.ToUpper(msg.Role[:1]) + msg.Role[1:]
		if len(msg.ToolCalls) > 0 {
			var tools []string
			for _, tc := range msg.ToolCalls {
				tools = append(tools, tc.Name)
			}
			content += fmt.Sprintf(" [Tools: %s]", strings.Join(tools, ", "))
		}

		parts = append(parts, fmt.Sprintf("[%d] %s: %s", i+1, roleName, content))
	}

	return strings.Join(parts, "\n")
}

// createStatisticalSummary åˆ›å»ºç»Ÿè®¡æ‘˜è¦
func (mp *MessageProcessor) createStatisticalSummary(messages []*session.Message) *session.Message {
	var userActions, toolUsages, keyTopics []string

	for _, msg := range messages {
		switch msg.Role {
		case "user":
			content := msg.Content
			if len(content) > 50 {
				content = content[:50] + "..."
			}
			userActions = append(userActions, content)
		case "assistant":
			for _, tc := range msg.ToolCalls {
				toolUsages = append(toolUsages, tc.Name)
			}
		case "tool":
			if toolName, ok := msg.Metadata["tool_name"].(string); ok {
				success := "âœ“"
				if toolSuccess, ok := msg.Metadata["tool_success"].(bool); ok && !toolSuccess {
					success = "âœ—"
				}
				keyTopics = append(keyTopics, fmt.Sprintf("%s%s", success, toolName))
			}
		}
	}

	var parts []string
	parts = append(parts, fmt.Sprintf("## Conversation Summary (%d messages)", len(messages)))

	if len(userActions) > 0 {
		parts = append(parts, fmt.Sprintf("**User Requests**: %s", strings.Join(userActions, "; ")))
	}

	if len(toolUsages) > 0 {
		toolCount := make(map[string]int)
		for _, tool := range toolUsages {
			toolCount[tool]++
		}
		var toolSummary []string
		for tool, count := range toolCount {
			if count > 1 {
				toolSummary = append(toolSummary, fmt.Sprintf("%s(%d)", tool, count))
			} else {
				toolSummary = append(toolSummary, tool)
			}
		}
		parts = append(parts, fmt.Sprintf("**Tools Used**: %s", strings.Join(toolSummary, ", ")))
	}

	if len(keyTopics) > 0 {
		parts = append(parts, fmt.Sprintf("**Key Activities**: %s", strings.Join(keyTopics, ", ")))
	}

	return &session.Message{
		Role:    "system",
		Content: strings.Join(parts, "\n"),
		Metadata: map[string]interface{}{
			"type":               "statistical_summary",
			"original_count":     len(messages),
			"summary_timestamp":  time.Now().Unix(),
			"compression_method": "statistical",
		},
		Timestamp: time.Now(),
	}
}

// ========== ä¼šè¯ç®¡ç† ==========

// GetCurrentSession è·å–å½“å‰ä¼šè¯
func (mp *MessageProcessor) GetCurrentSession(ctx context.Context, agent *ReactAgent) *session.Session {
	if agent.currentSession != nil {
		return agent.currentSession
	}

	// å°è¯•ä»contextä¸­è·å–session ID
	if sessionID, ok := ctx.Value(SessionIDKey).(string); ok && sessionID != "" {
		sess, err := mp.sessionManager.RestoreSession(sessionID)
		if err == nil {
			agent.mu.Lock()
			agent.currentSession = sess
			agent.mu.Unlock()
			return sess
		}
		log.Printf("[WARNING] Failed to restore session %s: %v", sessionID, err)
	}

	return nil
}

// GetContextStats è·å–ä¸Šä¸‹æ–‡ç»Ÿè®¡ä¿¡æ¯
func (mp *MessageProcessor) GetContextStats(sess *session.Session) *contextmgr.ContextStats {
	if mp.contextMgr == nil || sess == nil {
		return &contextmgr.ContextStats{
			TotalMessages:   0,
			EstimatedTokens: 0,
		}
	}
	return mp.contextMgr.GetContextStats(sess)
}

// RestoreFullContext æ¢å¤å®Œæ•´ä¸Šä¸‹æ–‡
func (mp *MessageProcessor) RestoreFullContext(sess *session.Session, backupID string) error {
	if mp.contextMgr == nil {
		return fmt.Errorf("context manager not available")
	}
	return mp.contextMgr.RestoreFullContext(sess, backupID)
}

// addTaskInstructions æ·»åŠ ä»»åŠ¡æŒ‡ä»¤

// ========== éšæœºæ¶ˆæ¯ç”Ÿæˆ ==========

var processingMessages = []string{
	"Processing", "Thinking", "Learning", "Exploring", "Discovering",
	"Analyzing", "Computing", "Reasoning", "Planning", "Executing",
	"Optimizing", "Searching", "Understanding", "Crafting", "Creating",
	"Parsing", "Generating", "Evaluating", "Calculating", "Investigating",
}

var rng = rand.New(rand.NewSource(time.Now().UnixNano()))

// GetRandomProcessingMessage è·å–éšæœºå¤„ç†æ¶ˆæ¯
func GetRandomProcessingMessage() string {
	return "ğŸ‘¾ " + processingMessages[rng.Intn(len(processingMessages))] + "..."
}

// GetRandomProcessingMessageWithEmoji è·å–å¸¦emojiçš„éšæœºå¤„ç†æ¶ˆæ¯
func GetRandomProcessingMessageWithEmoji() string {
	return "âš¡ " + GetRandomProcessingMessage() + " please wait"
}
